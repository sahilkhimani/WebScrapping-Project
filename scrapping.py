# -*- coding: utf-8 -*-
"""Scrapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h08UCM5NFGsOICmC-3F_rtmNoKtBmKev
"""

#All required imports
from bs4 import BeautifulSoup
import lxml
import requests
import pandas as pd

serial = []
name = []
author = []
rating =[]

m=0
for i in range(110):
    print("PROCESSING PAGE NO: " + str(i+1))
    url = "https://www.goodreads.com/list/show/1.Best_Books_Ever?page="+str(i+1)
    source = requests.get(url).text
    soup = BeautifulSoup(source, 'lxml')
    for head in soup.findAll('tr', attrs={'itemtype':'http://schema.org/Book'}):
        m+=1
        serial.append(m)
        names = head.find('span', attrs={'itemprop': 'name'})
        authors = head.find('div', attrs={'class': 'authorName__container'})
        ratings = head.find('span', attrs={'class': 'minirating'})
        ratings.span.decompose()
        name.append(names.text)
        author.append(authors.a.span.text)
        rating.append(ratings.text[:5])
        
df = pd.DataFrame({'Serial':serial,'Book Name':name, 'Author Name':author, 'Ratings': rating})
df.to_csv('Books.csv', index=False, encoding='utf-8')

from google.colab import files
files.download("Books.csv")

df = pd.read_csv('Books.csv')
df

df.head()
df.info()